---
phase: 02-manifest-contract-vibes-and-conform
plan: 03
type: execute
wave: 3
depends_on: [02-02]
files_modified:
  - tests/test_manifest.py
  - tests/test_conform_unit.py
  - tests/fixtures/sample_manifest.json
autonomous: false
requirements: [EDIT-04, EDIT-05, VIBE-01, VIBE-02, VIBE-03, VIBE-04, CLI-04]

must_haves:
  truths:
    - "A valid manifest passes Pydantic validation and a malformed manifest raises ManifestError with field-level detail"
    - "All 18 VibeProfile instances exist and their parameters match the research tables"
    - "An identity LUT produces no visible color change when applied to a reference video frame via FFmpeg lut3d"
    - "The full conform pipeline produces a playable MP4 output from a hand-crafted manifest against a real video source"
    - "The --review flag pauses the CLI for user confirmation before conform proceeds"
  artifacts:
    - path: "tests/test_manifest.py"
      provides: "Unit tests for schema validation and loader"
      exports: []
    - path: "tests/test_conform_unit.py"
      provides: "Unit tests for LUT generation and pipeline module imports"
      exports: []
    - path: "tests/fixtures/sample_manifest.json"
      provides: "Hand-crafted manifest for integration testing"
      contains: "clips"
  key_links:
    - from: "tests/test_manifest.py"
      to: "src/cinecut/manifest/schema.py"
      via: "TrailerManifest.model_validate()"
      pattern: "model_validate"
    - from: "tests/test_conform_unit.py"
      to: "src/cinecut/conform/luts.py"
      via: "generate_cube_lut() with identity params"
      pattern: "generate_cube_lut"
---

<objective>
Write automated unit tests for the manifest schema and LUT generation, create a sample manifest fixture, and perform a human-verified end-to-end conform run against real video.

Purpose: Automated tests give Phase 4 confidence that the manifest contract is stable. The human verify confirms that FFmpeg lut3d + loudnorm + concat produces a watchable trailer with correct color grading and audio — something only a human can confirm.
Output: test_manifest.py, test_conform_unit.py, sample_manifest.json fixture, and a human-verified end-to-end conform run.
</objective>

<execution_context>
@/home/adamh/.claude/get-shit-done/workflows/execute-plan.md
@/home/adamh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/phases/02-manifest-contract-vibes-and-conform/02-01-SUMMARY.md
@.planning/phases/02-manifest-contract-vibes-and-conform/02-02-SUMMARY.md

<interfaces>
<!-- All Phase 2 contracts now implemented -->

From src/cinecut/manifest/schema.py:
```python
VALID_VIBES: frozenset[str]  # 18 lowercase entries
class TrailerManifest(BaseModel):
    schema_version: str; source_file: str; vibe: str; clips: list[ClipEntry]
class ClipEntry(BaseModel):
    source_start_s: float; source_end_s: float
    beat_type: Literal[...]  # 7 options
    act: Literal[...]        # 8 options
    transition: str = "hard_cut"; dialogue_excerpt: str = ""
```

From src/cinecut/manifest/loader.py:
```python
def load_manifest(path: Path) -> TrailerManifest: ...  # raises ManifestError
```

From src/cinecut/manifest/vibes.py:
```python
VIBE_PROFILES: dict[str, VibeProfile]  # 18 entries
```

From src/cinecut/conform/luts.py:
```python
def generate_cube_lut(title, size, temp_shift, saturation, contrast, brightness, output_path) -> Path: ...
def ensure_luts(vibe_name: str, lut_dir: Path) -> Path: ...
LUT_SIZE: int  # 33
```

From src/cinecut/conform/pipeline.py:
```python
def conform_manifest(manifest: TrailerManifest, source: Path, work_dir: Path) -> Path: ...
def extract_and_grade_clip(source, start_s, end_s, lut_path, lufs_target, output_path) -> Path: ...
MIN_LOUDNORM_DURATION_S: float  # 3.0
```

From src/cinecut/errors.py:
```python
class ManifestError(CineCutError): ...
class ConformError(CineCutError): ...
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write unit tests for manifest schema and LUT generation</name>
  <files>
    tests/test_manifest.py
    tests/test_conform_unit.py
    tests/fixtures/sample_manifest.json
  </files>
  <action>
    Create tests/fixtures/ directory if it does not exist.

    **tests/fixtures/sample_manifest.json** — a minimal but complete hand-crafted manifest with 3 clips (covering cold_open, act1, act3 acts and multiple beat types):
    ```json
    {
      "schema_version": "1.0",
      "source_file": "PLACEHOLDER_SOURCE",
      "vibe": "action",
      "clips": [
        {
          "source_start_s": 10.0,
          "source_end_s": 14.5,
          "beat_type": "inciting_incident",
          "act": "cold_open",
          "transition": "hard_cut",
          "dialogue_excerpt": "Something has gone wrong."
        },
        {
          "source_start_s": 45.0,
          "source_end_s": 50.0,
          "beat_type": "escalation_beat",
          "act": "act1",
          "transition": "hard_cut",
          "dialogue_excerpt": ""
        },
        {
          "source_start_s": 120.0,
          "source_end_s": 122.0,
          "beat_type": "money_shot",
          "act": "act3",
          "transition": "hard_cut",
          "dialogue_excerpt": ""
        }
      ]
    }
    ```
    Note: source_start_s values are arbitrary placeholders — the test against real video in the human-verify step will use a real source path.

    **tests/test_manifest.py** — unit tests for schema and loader:
    ```python
    import json
    import tempfile
    from pathlib import Path
    import pytest
    from cinecut.manifest.schema import TrailerManifest, ClipEntry, VALID_VIBES
    from cinecut.manifest.loader import load_manifest
    from cinecut.manifest.vibes import VIBE_PROFILES, VibeProfile
    from cinecut.errors import ManifestError

    FIXTURE = Path(__file__).parent / "fixtures" / "sample_manifest.json"

    class TestValidManifest:
        def test_load_fixture(self):
            data = json.loads(FIXTURE.read_text())
            data["source_file"] = "/fake/path.mkv"
            m = TrailerManifest.model_validate(data)
            assert m.vibe == "action"
            assert len(m.clips) == 3

        def test_vibe_normalization(self):
            m = TrailerManifest.model_validate({
                "source_file": "/f.mkv", "vibe": "Action",
                "clips": [{"source_start_s": 0.0, "source_end_s": 5.0, "beat_type": "breath", "act": "act1"}]
            })
            assert m.vibe == "action"

        def test_scifi_alias(self):
            """'scifi' without hyphen should normalize to 'sci-fi'"""
            m = TrailerManifest.model_validate({
                "source_file": "/f.mkv", "vibe": "scifi",
                "clips": [{"source_start_s": 0.0, "source_end_s": 5.0, "beat_type": "breath", "act": "act1"}]
            })
            assert m.vibe == "sci-fi"

        def test_valid_vibes_count(self):
            assert len(VALID_VIBES) == 18

        def test_load_from_file(self, tmp_path):
            data = json.loads(FIXTURE.read_text())
            data["source_file"] = "/fake/path.mkv"
            p = tmp_path / "manifest.json"
            p.write_text(json.dumps(data))
            m = load_manifest(p)
            assert isinstance(m, TrailerManifest)

    class TestInvalidManifest:
        def test_missing_source_file(self):
            with pytest.raises(Exception):  # pydantic ValidationError or ManifestError
                TrailerManifest.model_validate({"vibe": "action", "clips": []})

        def test_end_before_start(self):
            with pytest.raises(Exception):
                TrailerManifest.model_validate({
                    "source_file": "/f.mkv", "vibe": "action",
                    "clips": [{"source_start_s": 5.0, "source_end_s": 3.0, "beat_type": "breath", "act": "act1"}]
                })

        def test_invalid_vibe(self):
            with pytest.raises(Exception):
                TrailerManifest.model_validate({
                    "source_file": "/f.mkv", "vibe": "nonexistent_vibe",
                    "clips": [{"source_start_s": 0.0, "source_end_s": 5.0, "beat_type": "breath", "act": "act1"}]
                })

        def test_invalid_json_raises_manifest_error(self, tmp_path):
            bad_json = tmp_path / "bad.json"
            bad_json.write_text("not json at all {{{")
            with pytest.raises(ManifestError):
                load_manifest(bad_json)

        def test_empty_clips_rejected(self):
            with pytest.raises(Exception):
                TrailerManifest.model_validate({"source_file": "/f.mkv", "vibe": "action", "clips": []})

    class TestVibeProfiles:
        def test_all_18_profiles_present(self):
            assert len(VIBE_PROFILES) == 18

        def test_keys_match_valid_vibes(self):
            assert set(VIBE_PROFILES.keys()) == VALID_VIBES

        def test_all_profiles_are_vibe_profile_instances(self):
            for name, p in VIBE_PROFILES.items():
                assert isinstance(p, VibeProfile), f"{name} is not VibeProfile"

        def test_profile_name_matches_key(self):
            for name, p in VIBE_PROFILES.items():
                assert p.name == name

        @pytest.mark.parametrize("vibe,expected_lufs", [
            ("action", -14.0), ("horror", -20.0), ("documentary", -20.0),
            ("drama", -18.0), ("thriller", -16.0),
        ])
        def test_lufs_targets(self, vibe, expected_lufs):
            assert VIBE_PROFILES[vibe].lufs_target == expected_lufs

        def test_action_color_params(self):
            a = VIBE_PROFILES["action"]
            assert a.temp_shift == -0.05
            assert a.saturation == 1.15
            assert a.contrast == 1.20
            assert a.act3_avg_cut_s == 1.2

        def test_lut_filenames_are_cube_files(self):
            for name, p in VIBE_PROFILES.items():
                assert p.lut_filename.endswith(".cube"), f"{name} lut_filename missing .cube"
    ```

    **tests/test_conform_unit.py** — unit tests for LUT generation:
    ```python
    import tempfile
    from pathlib import Path
    import pytest
    from cinecut.conform.luts import generate_cube_lut, ensure_luts, LUT_SIZE

    class TestGenerateCubeLut:
        def test_identity_lut_format(self, tmp_path):
            p = generate_cube_lut("identity", 2, 0.0, 1.0, 1.0, 0.0, tmp_path / "id.cube")
            lines = p.read_text().splitlines()
            assert lines[0] == 'TITLE "identity"'
            assert lines[1] == "LUT_3D_SIZE 2"
            assert lines[2] == "DOMAIN_MIN 0.0 0.0 0.0"
            assert lines[3] == "DOMAIN_MAX 1.0 1.0 1.0"

        def test_identity_r_fastest(self, tmp_path):
            """R must be the fastest-changing index (innermost loop) per .cube spec"""
            p = generate_cube_lut("identity", 2, 0.0, 1.0, 1.0, 0.0, tmp_path / "id.cube")
            data = [l for l in p.read_text().splitlines()[4:] if l.strip()]
            assert len(data) == 8  # 2^3
            # B=0,G=0,R=0 -> black
            assert data[0] == "0.000000 0.000000 0.000000"
            # B=0,G=0,R=1 -> red (R fastest)
            assert data[1] == "1.000000 0.000000 0.000000", f"Expected red at index 1, got: {data[1]}"
            # B=0,G=1,R=0 -> green
            assert data[2] == "0.000000 1.000000 0.000000"
            # B=1,G=0,R=0 -> blue (B slowest)
            assert data[4] == "0.000000 0.000000 1.000000"

        def test_lut_size_33(self, tmp_path):
            p = generate_cube_lut("test", LUT_SIZE, 0.0, 1.0, 1.0, 0.0, tmp_path / "t.cube")
            data = [l for l in p.read_text().splitlines()[4:] if l.strip()]
            assert len(data) == LUT_SIZE ** 3

        def test_ensure_luts_idempotent(self, tmp_path):
            p1 = ensure_luts("action", tmp_path)
            p2 = ensure_luts("action", tmp_path)
            assert p1 == p2
            assert p1.exists()

        def test_ensure_luts_creates_dir(self, tmp_path):
            lut_dir = tmp_path / "deep" / "luts"
            assert not lut_dir.exists()
            p = ensure_luts("drama", lut_dir)
            assert p.exists()

        def test_ensure_luts_unknown_vibe(self, tmp_path):
            with pytest.raises(ValueError, match="Unknown vibe"):
                ensure_luts("nonexistent", tmp_path)
    ```

    Run tests:
    ```bash
    cd /home/adamh/ai-video-trailer && python3 -m pytest tests/test_manifest.py tests/test_conform_unit.py -v 2>&1
    ```
    All tests must pass.
  </action>
  <verify>
    <automated>cd /home/adamh/ai-video-trailer && python3 -m pytest tests/test_manifest.py tests/test_conform_unit.py -v 2>&1 | tail -20</automated>
  </verify>
  <done>
    - tests/fixtures/sample_manifest.json exists with 3 well-formed clips
    - test_manifest.py: all tests pass (valid manifests load, invalid manifests raise, all 18 vibes present, vibe normalization works)
    - test_conform_unit.py: all tests pass (identity LUT format correct, R-fastest verified, LUT size 33^3, ensure_luts idempotent)
    - pytest exits 0 with all tests passing
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Human verify end-to-end Phase 2 pipeline</name>
  <what-built>
    Complete Phase 2 pipeline:
    - Pydantic manifest schema (TrailerManifest, ClipEntry) with 18 vibe validation
    - All 18 VibeProfile instances with color/audio/pacing parameters
    - Programmatic .cube LUT generation (NumPy, 33^3, correct R-inner B-outer order)
    - FFmpeg conform pipeline: frame-accurate extraction + lut3d + two-pass loudnorm + concat
    - CLI --manifest and --review flags wired to conform stages
    - Automated tests for schema and LUT generation (all passing)
  </what-built>
  <how-to-verify>
    **Step 1: Run automated tests**
    ```
    cd /home/adamh/ai-video-trailer
    python3 -m pytest tests/test_manifest.py tests/test_conform_unit.py -v
    ```
    Expected: All tests pass with green output.

    **Step 2: Verify schema import and vibe profiles**
    ```
    python3 -c "
    from cinecut.manifest.schema import VALID_VIBES
    from cinecut.manifest.vibes import VIBE_PROFILES
    print(f'Vibes: {len(VALID_VIBES)} valid, {len(VIBE_PROFILES)} profiles')
    print('Action LUFS:', VIBE_PROFILES['action'].lufs_target)
    print('Horror brightness:', VIBE_PROFILES['horror'].brightness)
    "
    ```
    Expected: "Vibes: 18 valid, 18 profiles", action LUFS -14.0, horror brightness -0.05

    **Step 3: Verify LUT file generates correctly**
    ```
    python3 -c "
    import tempfile, pathlib
    from cinecut.conform.luts import ensure_luts
    d = pathlib.Path(tempfile.mkdtemp())
    p = ensure_luts('action', d)
    lines = p.read_text().splitlines()
    print('LUT header:', lines[:4])
    print('Data lines:', len([l for l in lines[4:] if l.strip()]))
    "
    ```
    Expected: Header shows TITLE/LUT_3D_SIZE 33/DOMAIN_MIN/DOMAIN_MAX; data lines = 35937 (33^3)

    **Step 4: CLI --help shows new flags**
    ```
    cinecut --help
    ```
    Expected: --manifest/-m and --review options visible in help output.

    **Step 5 (if test video available): End-to-end conform with hand-crafted manifest**
    If you have a test video file available (any MKV/AVI/MP4):
    a. Update tests/fixtures/sample_manifest.json: replace "PLACEHOLDER_SOURCE" with the actual absolute path to your test video, and adjust source_start_s/source_end_s to valid timestamps within the video.
    b. Run:
    ```
    cinecut /path/to/test.mkv --subtitle /path/to/test.srt --vibe action --manifest tests/fixtures/sample_manifest.json
    ```
    Expected: CLI runs conform, produces `test_trailer_action.mp4` next to the source file.
    c. Play the output: `ffplay test_trailer_action.mp4`
    Expected: Playable video with the action LUT applied (slightly cool, boosted saturation and contrast), clean audio.

    **Step 6 (if test video available): Test --review flag**
    ```
    cinecut /path/to/test.mkv --subtitle /path/to/test.srt --vibe action --manifest tests/fixtures/sample_manifest.json --review
    ```
    Expected: CLI prints manifest path and prompts "Proceed with FFmpeg conform? [y/N]". Entering 'n' aborts without producing output. Entering 'y' proceeds to conform.
  </how-to-verify>
  <resume-signal>
    If Steps 1-4 all pass and (if test video was available) Step 5-6 produce a playable output with visible LUT effect and the --review prompt works correctly: type "approved".

    If any step fails: describe the failure and which step it occurred at.
  </resume-signal>
  <files>no files modified by this checkpoint</files>
  <action>Present the how-to-verify steps to the user and pause for their response.</action>
  <verify>User types "approved" to confirm Phase 2 end-to-end pipeline works correctly.</verify>
  <done>User has confirmed: automated tests pass, 18 vibe profiles importable, LUT generates 35937 lines, CLI --help shows --manifest and --review, and (if video available) conform produces a playable output.</done>
</task>

</tasks>

<verification>
Phase 2 complete when:
- pytest tests/test_manifest.py tests/test_conform_unit.py exits 0 (all green)
- All 18 vibes importable from VIBE_PROFILES with correct parameters
- LUT generation produces valid 33^3 .cube files with correct R-inner ordering
- CLI --help shows --manifest and --review
- Human has confirmed end-to-end conform produces a playable trailer (or confirmed Steps 1-4 pass if no test video available)
</verification>

<success_criteria>
- All automated tests pass: schema validation, vibe profiles, LUT generation correctness
- Schema rejects malformed manifests (missing fields, bad types, end <= start, invalid vibe, empty clips)
- Schema accepts all 18 vibe names with normalization (case, hyphen variants)
- LUT generation: identity LUT has correct R-inner B-outer ordering verified by data line content
- Human has verified end-to-end conform pipeline (or confirmed CLI/schema/LUT checks pass where no test video available)
</success_criteria>

<output>
After completion, create `.planning/phases/02-manifest-contract-vibes-and-conform/02-03-SUMMARY.md`
</output>
