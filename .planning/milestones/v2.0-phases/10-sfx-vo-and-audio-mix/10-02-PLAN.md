---
phase: 10-sfx-vo-and-audio-mix
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/cinecut/conform/vo_extract.py
autonomous: true
requirements:
  - VONR-01
  - VONR-02
  - VONR-03
must_haves:
  truths:
    - "Protagonist is identified as the most-speaking character from ASS subtitle event.name field"
    - "For SRT input (no speaker names), protagonist identification returns None and VO extraction is skipped gracefully"
    - "Up to 3 VO clips are extracted: 1 from BEGINNING zone (Act 1), up to 2 from ESCALATION zone (Act 2), 0 from CLIMAX (Act 3)"
    - "VO clips shorter than 0.8s are rejected — minimum duration enforced before extraction"
    - "All VO clips re-encoded to AAC 48000Hz stereo using output-seeking FFmpeg (-ss before -i)"
    - "VO extracted from original source file, never from the 420p proxy"
  artifacts:
    - path: "src/cinecut/conform/vo_extract.py"
      provides: "identify_protagonist(), extract_vo_clips() — protagonist VO extraction"
      exports:
        - "identify_protagonist"
        - "extract_vo_clips"
        - "VoClip"
  key_links:
    - from: "src/cinecut/conform/vo_extract.py"
      to: "pysubs2.load(subtitle_path)"
      via: "identify_protagonist() — loads ASS/SRT, counts event.name occurrences"
      pattern: "Counter.*event.name"
    - from: "src/cinecut/conform/vo_extract.py"
      to: "work_dir/vo/vo_N.aac"
      via: "extract_vo_clips() — FFmpeg output-seeking extraction per VO candidate"
      pattern: "ffmpeg.*-ss.*-i.*-vn.*-c:a aac.*-ar 48000"
    - from: "src/cinecut/conform/vo_extract.py"
      to: "TrailerManifest.clips[*].act + structural_anchors"
      via: "find subtitle events overlapping BEGINNING/ESCALATION zone timestamps"
      pattern: "source_start_s.*source_end_s"
---

<objective>
Implement `conform/vo_extract.py` — protagonist identification and VO audio clip extraction from the source film, placing up to 3 clips from Acts 1 and 2 only.

Purpose: Fulfils VONR-01, VONR-02, VONR-03 — protagonist identification via pysubs2 SSAEvent.name, output-seeking FFmpeg extraction, 0.8s minimum, AAC 48000Hz re-encode.
Output: `src/cinecut/conform/vo_extract.py` — two public functions consumed by Phase 10 Plan 03.
</objective>

<execution_context>
@/home/adamh/.claude/get-shit-done/workflows/execute-plan.md
@/home/adamh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-sfx-vo-and-audio-mix/10-RESEARCH.md

<interfaces>
<!-- Key types and contracts from existing codebase. Executor uses these directly. -->

From src/cinecut/manifest/schema.py:
```python
class ClipEntry(BaseModel):
    source_start_s: float       # start in source film seconds
    source_end_s: float         # end in source film seconds
    act: Literal["cold_open","act1","beat_drop","act2","breath","act3","title_card","button"]
    transition: Literal["hard_cut", "crossfade", "fade_to_black", "fade_to_white"] = "hard_cut"
    dialogue_excerpt: str = ""
    # Phase 8 addition (may be None if Phase 8 not yet executed):
    narrative_zone: Optional[Literal["BEGINNING", "ESCALATION", "CLIMAX"]] = None

class TrailerManifest(BaseModel):
    schema_version: str
    source_file: str
    vibe: str
    clips: list[ClipEntry]
    # Phase 7 addition:
    structural_anchors: Optional[StructuralAnchors] = None
    # Phase 9 additions:
    bpm_grid: Optional[BpmGrid] = None
    music_bed: Optional[MusicBed] = None
```

VO zone mapping:
- Act 1 zones: clips where act in {"cold_open", "act1"} OR narrative_zone == "BEGINNING"
- Act 2 zones: clips where act in {"beat_drop", "act2"} OR narrative_zone == "ESCALATION"
- Act 3 zones: clips where act in {"breath", "act3"} OR narrative_zone == "CLIMAX" — NO VO from these

pysubs2 API (already in pyproject.toml):
```python
import pysubs2
subs = pysubs2.load(str(subtitle_path), encoding="utf-8")
# Each event: event.name (str, empty for SRT), event.text (str), event.is_comment (bool)
# event.start (int, milliseconds), event.end (int, milliseconds)
```

From src/cinecut/errors.py:
```python
class ConformError(CineCutError):
    def __init__(self, path: Path, stderr: str) -> None: ...
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create conform/vo_extract.py — protagonist identification and VO clip extraction</name>
  <files>src/cinecut/conform/vo_extract.py</files>
  <action>
Create `src/cinecut/conform/vo_extract.py` with the following:

**Dataclass:**
```python
from dataclasses import dataclass

@dataclass
class VoClip:
    path: Path           # path to extracted .aac file
    timeline_s: float    # position in trailer timeline where this VO should play
    act_zone: str        # "act1" or "act2"
```

**`identify_protagonist(subtitle_path: Path) -> str | None`:**
- Load subtitle file with `pysubs2.load(str(subtitle_path), encoding="utf-8")`
- Collect speaker names: `[e.name.strip() for e in subs if not e.is_comment and e.name.strip()]`
- If list is empty (SRT file or ASS with no speaker attribution), return `None`
- Return `Counter(names).most_common(1)[0][0]` — the most frequently named speaker
- Do NOT strip SSA style codes from names (keep simple; style codes in `event.name` are rare and would appear as a consistent name pattern anyway)

**`extract_vo_clips(manifest: TrailerManifest, source: Path, subtitle_path: Path, work_dir: Path) -> list[VoClip]`:**
- Determine protagonist: call `identify_protagonist(subtitle_path)`
  - If `None`: check `manifest.structural_anchors` for a `protagonist` field (if Phase 7 stored it); if still `None`, log a warning and return `[]` (graceful degradation)
- Create `work_dir/vo/` directory
- Load subtitle file again with pysubs2 to get all events with timing
- Build timeline map: compute each clip's trailer-timeline start position by accumulating preceding clip durations
  - `timeline_offsets[i] = sum(c.source_end_s - c.source_start_s for c in manifest.clips[:i])`
- Determine zone boundaries from manifest clips:
  - Act 1 clips: `act in {"cold_open", "act1"}` (these define the BEGINNING zone in the trailer timeline)
  - Act 2 clips: `act in {"beat_drop", "act2"}` (ESCALATION zone)
  - Act 3 clips: `act in {"breath", "act3"}` — no VO
- For each zone (act1 first, then act2), find subtitle events whose timing overlaps a clip from that zone in the SOURCE film:
  - `event.start / 1000.0 >= clip.source_start_s and event.end / 1000.0 <= clip.source_end_s`
  - Event speaker must match protagonist (case-insensitive comparison)
  - Event duration must be `(event.end - event.start) / 1000.0 >= 0.8` (VONR-03 minimum)
- Select candidates: for Act 1, pick up to 1 candidate (highest duration); for Act 2, pick up to 2 candidates (highest durations). If no protagonist events in a zone, skip (no VO for that act — do not reach outside zone).
- For each selected candidate, compute:
  - `start_s = event.start / 1000.0`
  - `end_s = event.end / 1000.0`
  - `duration = end_s - start_s`
  - Find which clip this event falls within and compute timeline position: `timeline_s = timeline_offsets[clip_index] + (start_s - clip.source_start_s)`
- Extract audio using output-seeking FFmpeg (VONR-03):
  ```
  ffmpeg -y -ss START_S -i SOURCE -t DURATION -vn -c:a aac -ar 48000 -ac 2 -b:a 192k OUTPUT.aac
  ```
  - `-ss` BEFORE `-i` = output-seeking (accurate for audio re-encode)
  - Source is the ORIGINAL source film path, NOT the proxy
  - Output path: `work_dir/vo/vo_{N}.aac` where N is sequential (0, 1, 2)
  - If FFmpeg returncode != 0, log warning and skip this clip (graceful degradation — do not raise)
- Return list of `VoClip` for successfully extracted clips

**Import block:**
```python
import subprocess
import logging
from collections import Counter
from dataclasses import dataclass
from pathlib import Path
import pysubs2
from cinecut.manifest.schema import TrailerManifest
```

Do NOT import from pipeline.py or sfx.py — keep vo_extract.py self-contained.

**Logging:** Use `logging.getLogger(__name__)` for all warnings (no Rich console usage — that's CLI-layer only).
  </action>
  <verify>
    <automated>cd /home/adamh/ai-video-trailer && python -c "from cinecut.conform.vo_extract import identify_protagonist, extract_vo_clips, VoClip; print('import ok')"</automated>
  </verify>
  <done>
    - `from cinecut.conform.vo_extract import identify_protagonist, extract_vo_clips, VoClip` succeeds
    - `identify_protagonist` accepts `subtitle_path: Path`, returns `str | None`
    - `extract_vo_clips` accepts `(manifest, source, subtitle_path, work_dir)`, returns `list[VoClip]`
    - `VoClip` has `path`, `timeline_s`, `act_zone` fields
    - `identify_protagonist` returns `None` when all `event.name` fields are empty (SRT case)
    - `-ss` placed BEFORE `-i` in FFmpeg command (output-seeking, not input-seeking)
    - Minimum 0.8s duration enforced BEFORE calling FFmpeg
    - Act 3 clips excluded from VO candidate selection
    - Source film path used for extraction (not proxy)
  </done>
</task>

</tasks>

<verification>
Run from `/home/adamh/ai-video-trailer`:
```bash
python -c "from cinecut.conform.vo_extract import identify_protagonist, extract_vo_clips, VoClip; print('ok')"
python -m pytest tests/ -x -q --tb=short 2>&1 | tail -10
```
No import errors, existing tests pass.
</verification>

<success_criteria>
- `src/cinecut/conform/vo_extract.py` exists and imports cleanly
- `identify_protagonist()` uses `Counter(event.name)` with empty-string guard
- `extract_vo_clips()` enforces 0.8s minimum before FFmpeg call
- `-ss` placed before `-i` in all FFmpeg extraction commands (output-seeking)
- VO extracted from original source, not proxy
- Act 3 clips produce no VO candidates
- Graceful degradation: returns `[]` when protagonist is None (MUSC-03 pattern)
- pysubs2 is the only non-stdlib import (already in pyproject.toml)
</success_criteria>

<output>
After completion, create `.planning/phases/10-sfx-vo-and-audio-mix/10-02-SUMMARY.md`
</output>
