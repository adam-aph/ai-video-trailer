# CineCut AI

## What This Is

A Python 3.10+ CLI tool that performs AI-driven narrative extraction from full-length feature films to generate a stylized 2-minute trailer based on a user-defined "Vibe Profile." The system runs a three-tier pipeline: analysis proxy creation → multimodal narrative inference via local LLaVA/llama-cli → high-bitrate conform against the original source file. No cloud dependencies — everything runs locally on a Quadro K6000.

## Core Value

Given a feature film and its subtitle file, produce a narratively coherent, vibe-styled trailer that a human editor would be proud to show — technically clean output with a real beginning, escalation, and climax arc.

## Requirements

### Validated

(None yet — ship to validate)

### Active

- [ ] Three-tier pipeline: 420p analysis proxy → multimodal inference → high-bitrate conform
- [ ] 18 vibe profiles (Action, Adventure, Animation, Comedy, Crime, Documentary, Drama, Family, Fantasy, History, Horror, Music, Mystery, Romance, Sci-Fi, Thriller, War, Western)
- [ ] Each vibe has an Edit Profile (avg cut length, audio treatment, transition style)
- [ ] LLaVA vision model integration via llama-cli for keyframe scene analysis
- [ ] SRT/ASS subtitle file as primary narrative signal (always provided by user)
- [ ] Narrative beat extraction: Inciting Incident, Climax Beats, Money Shots
- [ ] TRAILER_MANIFEST.json generated by AI with all clip decisions
- [ ] `--review` flag pauses pipeline after manifest generation for human inspection/edit
- [ ] Default mode: fully automatic (manifest → conform without pause)
- [ ] LUT sourcing and creation for all 18 vibes (.cube files)
- [ ] Frame-accurate FFmpeg seeking (-ss before -i)
- [ ] Audio normalization with LUFS targeting per vibe
- [ ] LUT application via FFmpeg based on vibe selection
- [ ] CLI interface: `cinecut <video> --vibe <name> [--review]`

### Out of Scope

- Cloud inference or remote API calls — local-only by constraint
- Subtitle generation / speech-to-text — user always provides subtitle file
- Mobile or web interface — CLI only
- Real-time preview during editing — manifest-based workflow only
- Multi-GPU or distributed processing — single Quadro K6000

## Context

- **Hardware:** Nvidia Quadro K6000 (12GB VRAM) | Driver 470.256.02 | CUDA 11.4
- **Inference engine:** llama-cli pre-configured on system; must be primary engine
- **VRAM budget:** 12GB shared between LLaVA model inference and FFmpeg processes — prompt engineering must stay within this headroom
- **Input:** MKV/AVI/MP4 video file + SRT/ASS subtitle file
- **Output:** ~2-minute MP4 trailer at source resolution/bitrate
- **Manifest architecture:** TRAILER_MANIFEST.json is the AI output artifact, enabling human override before final render
- **LUTs:** Not yet available — need to be sourced from free/open libraries or procedurally generated per vibe

## Constraints

- **GPU/CUDA:** Quadro K6000, CUDA 11.4 — no newer CUDA features; llama-cli must be CUDA 11.4 compatible
- **Inference:** llama-cli is the only inference backend; no Ollama, no Python-native model loading
- **VRAM:** 12GB hard ceiling for all concurrent processes
- **Subtitles:** Always SRT or ASS format — system does not need to handle subtitle-less input
- **Python version:** 3.10+ (use match/case, modern type hints where appropriate)
- **Dependencies:** FFmpeg must be available on PATH; no bundled binaries

## Key Decisions

| Decision | Rationale | Outcome |
|----------|-----------|---------|
| LLaVA vision model via llama-cli (not text-only) | Keyframes analyzed as images — richer scene description than subtitle-only | — Pending |
| SRT/ASS as always-present input | Simplifies narrative extraction; user workflow always has subtitles available | — Pending |
| JSON manifest as pipeline intermediary | Enables human override before expensive high-res conform; also a debugging artifact | — Pending |
| `--review` flag for manifest inspection (not default pause) | Default auto mode is fast path; `--review` is explicit opt-in for editorial control | — Pending |
| LUTs need to be sourced/created | 18 vibe-specific .cube files not yet available; sourcing is part of project scope | — Pending |
| 420p analysis proxy | Hardware-constrained — reduces FFmpeg memory pressure during inference pipeline | — Pending |

---
*Last updated: 2026-02-26 after initialization*
