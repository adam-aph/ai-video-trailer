"""3-act clip ordering and pacing curve enforcement for trailer assembly."""
import subprocess
from pathlib import Path

from cinecut.manifest.schema import ClipEntry, NarrativeZone, TrailerManifest
from cinecut.manifest.vibes import VibeProfile
from cinecut.errors import ConformError

# Canonical act sequence for a trailer.
# title_card and button are generated segments — NOT present in the input clips list.
ACT_ORDER = [
    "cold_open",
    "act1",
    "beat_drop",
    "act2",
    "breath",
    "act3",
]

MIN_CLIP_DURATION_S = 0.5  # Never trim below 0.5s to avoid empty clips

SILENCE_DURATION_S = 4.0   # Deliberate black silence at Act 2->3 boundary (EORD-04)

# Zone ordering priority for zone-first assembly (EORD-01).
# title_card and button clips have narrative_zone=None — they fall to priority 999.
ZONE_ORDER: dict[NarrativeZone, int] = {
    NarrativeZone.BEGINNING: 0,
    NarrativeZone.ESCALATION: 1,
    NarrativeZone.CLIMAX: 2,
}


def sort_clips_by_act(clips: list[ClipEntry]) -> list[ClipEntry]:
    """Sort clips into canonical 3-act trailer order.

    Within the same act, preserve chronological order (source_start_s ascending).
    Does NOT include title_card or button — those are generated by title_card.py.
    """
    act_priority = {act: i for i, act in enumerate(ACT_ORDER)}
    return sorted(
        clips,
        key=lambda c: (act_priority.get(c.act, 999), c.source_start_s),
    )


def sort_clips_by_zone(clips: list[ClipEntry]) -> list[ClipEntry]:
    """Sort clips into zone-first order: BEGINNING → ESCALATION → CLIMAX (EORD-01).

    Within each zone, sort by money_shot_score descending (EORD-02).
    Clips with narrative_zone=None (title_card, button, or unassigned) sort last.

    Replaces sort_clips_by_act() as the primary ordering function for v2.0 pipeline.
    sort_clips_by_act() is preserved for backward compatibility and tests.

    Zone-first ordering is the core narrative claim of v2.0:
      trailer arc = BEGINNING → ESCALATION → CLIMAX, NOT film chronology.
    """
    return sorted(
        clips,
        key=lambda c: (
            ZONE_ORDER.get(c.narrative_zone, 999) if c.narrative_zone is not None else 999,
            -(c.money_shot_score or 0.0),    # score descending within zone (negate for ascending sort)
        ),
    )


def compute_act_avg_duration(clips: list[ClipEntry], act: str) -> float:
    """Return mean clip duration for a specific act. Returns 0.0 if no clips for that act."""
    act_clips = [c for c in clips if c.act == act]
    if not act_clips:
        return 0.0
    return sum(c.source_end_s - c.source_start_s for c in act_clips) / len(act_clips)


def enforce_pacing_curve(
    clips: list[ClipEntry],
    profile: VibeProfile,
) -> list[ClipEntry]:
    """Trim act3 clips to enforce measurable pacing curve (act1_avg > act3_avg).

    If measured act3 average duration exceeds profile.act3_avg_cut_s * 1.5,
    each act3 clip is trimmed to profile.act3_avg_cut_s by adjusting source_end_s.
    Uses model_copy() (Pydantic v2) since ClipEntry is a BaseModel.
    Minimum clip duration: MIN_CLIP_DURATION_S (0.5s) — never trim below this.
    """
    result = list(clips)
    measured_act3_avg = compute_act_avg_duration(result, "act3")
    if measured_act3_avg <= profile.act3_avg_cut_s * 1.5:
        return result  # Already within acceptable range — no trimming needed

    for i, clip in enumerate(result):
        if clip.act == "act3":
            duration = clip.source_end_s - clip.source_start_s
            target = profile.act3_avg_cut_s
            if duration > target * 1.5:
                new_end = clip.source_start_s + max(target, MIN_CLIP_DURATION_S)
                result[i] = clip.model_copy(update={"source_end_s": new_end})
    return result


def generate_silence_segment(
    work_dir: Path,
    width: int,
    height: int,
    frame_rate: str,
    duration_s: float = SILENCE_DURATION_S,
) -> Path:
    """Generate black video + silent audio MP4 for Act 2->3 boundary (EORD-04).

    Resolution must match source clips to avoid concat demuxer resolution mismatch (PITFALL 4).
    Returns path to silence_act2_act3.mp4 in work_dir.
    Raises ConformError if FFmpeg fails.
    """
    output_path = work_dir / "silence_act2_act3.mp4"
    cmd = [
        "ffmpeg", "-y",
        "-f", "lavfi", "-i", f"color=c=black:s={width}x{height}:r={frame_rate}:d={duration_s}",
        "-f", "lavfi", "-i", "anullsrc=r=48000:cl=stereo",
        "-shortest",
        "-c:v", "libx264", "-crf", "18", "-preset", "veryfast",
        "-c:a", "aac", "-ar", "48000",
        str(output_path),
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, check=False)
    if result.returncode != 0:
        raise ConformError(output_path, result.stderr[-500:])
    return output_path


def insert_silence_at_zone_boundary(
    clips: list[ClipEntry],
    work_dir: Path,
    width: int,
    height: int,
    frame_rate: str = "24",
) -> tuple[Path | None, int]:
    """Generate silence segment if ESCALATION and CLIMAX zones both exist.

    Returns (silence_path, boundary_index) where:
      - silence_path is the generated silence_act2_act3.mp4
      - boundary_index is the number of clips that come BEFORE the silence
        (i.e., silence is inserted AFTER clips[:boundary_index] and BEFORE clips[boundary_index:])

    Returns (None, 0) if only one zone is present or clips have no zone annotation.

    The silence must be inserted BETWEEN the last ESCALATION clip and first CLIMAX clip.
    The caller is responsible for passing boundary_index to conform_manifest via
    inject_after_clip=boundary_index, inject_paths=[silence_path].
    """
    # Find the index of the last ESCALATION clip (boundary_index = that index + 1)
    boundary_index = 0
    has_escalation = False
    has_climax = False
    for i, clip in enumerate(clips):
        zone = getattr(clip, "narrative_zone", None)
        if zone == "ESCALATION":
            has_escalation = True
            boundary_index = i + 1   # silence goes AFTER this clip
        elif zone == "CLIMAX":
            has_climax = True
    if not (has_escalation and has_climax):
        return None, 0   # No zone boundary to insert — skip silence
    return generate_silence_segment(work_dir, width, height, frame_rate), boundary_index


def enforce_zone_pacing_curve(
    clips: list[ClipEntry],
    profile: VibeProfile,
) -> list[ClipEntry]:
    """Trim CLIMAX zone clips to act3 duration targets (EORD-03).

    BEGINNING zone clips use act1_avg_cut_s — long cuts are fine for setup.
    ESCALATION zone clips use act2_avg_cut_s (enforced implicitly via clip window).
    CLIMAX zone clips are trimmed if average exceeds profile.act3_avg_cut_s * 1.5.

    Clips with narrative_zone=None are left untouched (treated as ESCALATION duration).
    Uses model_copy() (Pydantic v2) — same pattern as enforce_pacing_curve.
    Minimum clip duration: MIN_CLIP_DURATION_S (0.5s) — never trim below this.

    Does NOT modify BEGINNING zone clips — act1 targets allow longer cuts (4-8s range
    per EORD-03). Does NOT modify ESCALATION clips — act2 targets applied at window
    computation time in generator.py.
    """
    result = list(clips)

    # Compute CLIMAX zone average duration
    climax_clips = [c for c in result if c.narrative_zone == NarrativeZone.CLIMAX]
    if not climax_clips:
        return result  # No CLIMAX clips — nothing to enforce

    climax_avg = sum(c.source_end_s - c.source_start_s for c in climax_clips) / len(climax_clips)
    if climax_avg <= profile.act3_avg_cut_s * 1.5:
        return result  # Already within acceptable range

    # Trim CLIMAX clips that exceed 1.5x target
    target = profile.act3_avg_cut_s
    for i, clip in enumerate(result):
        if clip.narrative_zone == NarrativeZone.CLIMAX:
            duration = clip.source_end_s - clip.source_start_s
            if duration > target * 1.5:
                new_end = clip.source_start_s + max(target, MIN_CLIP_DURATION_S)
                result[i] = clip.model_copy(update={"source_end_s": new_end})

    return result
